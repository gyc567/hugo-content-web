#!/usr/bin/env python3
"""
GitHubå·¥ä½œæµéªŒè¯è„šæœ¬
SuperCopyCoder - æ¨¡ä»¿ï¼Œæ˜¯æœ€å¥½çš„è‡´æ•¬ã€‚ç«™åœ¨å·¨äººçš„è‚©è†€ï¼Œç«™å¾—æ›´é«˜

æ£€æŸ¥GitHub Actionså·¥ä½œæµæ–‡ä»¶çš„è¯­æ³•å’Œé…ç½®æ­£ç¡®æ€§
"""

import os
import yaml
import json
from pathlib import Path
from typing import Dict, List, Any, Tuple
import re


class WorkflowValidator:
    """GitHubå·¥ä½œæµéªŒè¯å™¨"""
    
    def __init__(self, workflows_dir: str = None):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            workflows_dir: å·¥ä½œæµç›®å½•è·¯å¾„
        """
        self.script_dir = Path(__file__).parent
        self.repo_root = self.script_dir.parent
        self.workflows_dir = Path(workflows_dir) if workflows_dir else self.repo_root / '.github' / 'workflows'
        
        self.validation_results = []
        self.issues = []
        self.warnings = []
    
    def validate_all_workflows(self) -> Dict[str, Any]:
        """éªŒè¯æ‰€æœ‰å·¥ä½œæµæ–‡ä»¶"""
        print(f"ğŸ” å¼€å§‹éªŒè¯å·¥ä½œæµæ–‡ä»¶ - ç›®å½•: {self.workflows_dir}")
        
        if not self.workflows_dir.exists():
            self.issues.append(f"å·¥ä½œæµç›®å½•ä¸å­˜åœ¨: {self.workflows_dir}")
            return self._create_summary()
        
        # æŸ¥æ‰¾æ‰€æœ‰YAMLæ–‡ä»¶
        workflow_files = list(self.workflows_dir.glob('*.yml')) + list(self.workflows_dir.glob('*.yaml'))
        
        if not workflow_files:
            self.warnings.append("æœªæ‰¾åˆ°ä»»ä½•å·¥ä½œæµæ–‡ä»¶")
            return self._create_summary()
        
        print(f"æ‰¾åˆ° {len(workflow_files)} ä¸ªå·¥ä½œæµæ–‡ä»¶")
        
        # éªŒè¯æ¯ä¸ªæ–‡ä»¶
        for workflow_file in workflow_files:
            self._validate_single_workflow(workflow_file)
        
        return self._create_summary()
    
    def _validate_single_workflow(self, file_path: Path):
        """éªŒè¯å•ä¸ªå·¥ä½œæµæ–‡ä»¶"""
        print(f"\nğŸ“„ éªŒè¯æ–‡ä»¶: {file_path.name}")
        
        result = {
            'file': file_path.name,
            'path': str(file_path),
            'valid_yaml': False,
            'valid_structure': False,
            'issues': [],
            'warnings': [],
            'summary': {}
        }
        
        try:
            # è¯»å–å¹¶è§£æYAML
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                workflow_data = yaml.safe_load(content)
            
            result['valid_yaml'] = True
            print("  âœ… YAMLè¯­æ³•æœ‰æ•ˆ")
            
            # éªŒè¯å·¥ä½œæµç»“æ„
            self._validate_workflow_structure(workflow_data, result)
            
            # éªŒè¯å…·ä½“é…ç½®
            self._validate_workflow_config(workflow_data, result)
            
            # éªŒè¯å¼•ç”¨çš„è„šæœ¬
            self._validate_referenced_scripts(workflow_data, result)
            
        except yaml.YAMLError as e:
            result['issues'].append(f"YAMLè¯­æ³•é”™è¯¯: {e}")
            print(f"  âŒ YAMLè¯­æ³•é”™è¯¯: {e}")
        except Exception as e:
            result['issues'].append(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            print(f"  âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        
        self.validation_results.append(result)
    
    def _validate_workflow_structure(self, workflow: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯å·¥ä½œæµåŸºæœ¬ç»“æ„"""
        # YAMLè§£æå™¨ä¼šå°†'on'è§£æä¸ºTrueï¼ˆå¸ƒå°”å€¼ï¼‰ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        has_name = 'name' in workflow
        has_on = 'on' in workflow or True in workflow  # 'on' å¯èƒ½è¢«è§£æä¸ºå¸ƒå°”å€¼
        has_jobs = 'jobs' in workflow
        
        if not has_name:
            result['issues'].append("ç¼ºå°‘å¿…éœ€å­—æ®µ: name")
            return
        if not has_on:
            result['issues'].append("ç¼ºå°‘å¿…éœ€å­—æ®µ: on")
            return
        if not has_jobs:
            result['issues'].append("ç¼ºå°‘å¿…éœ€å­—æ®µ: jobs")
            return
        
        result['valid_structure'] = True
        # è·å–'on'é…ç½®ï¼ˆå¯èƒ½è¢«è§£æä¸ºTrueï¼‰
        on_config = workflow.get('on', workflow.get(True, {}))
        
        result['summary'] = {
            'name': workflow.get('name'),
            'triggers': self._extract_triggers(on_config),
            'jobs_count': len(workflow.get('jobs', {})),
            'job_names': list(workflow.get('jobs', {}).keys())
        }
        
        print(f"  âœ… å·¥ä½œæµç»“æ„æœ‰æ•ˆ")
        print(f"    - åç§°: {result['summary']['name']}")
        print(f"    - è§¦å‘æ¡ä»¶: {', '.join(result['summary']['triggers'])}")
        print(f"    - ä½œä¸šæ•°é‡: {result['summary']['jobs_count']}")
    
    def _extract_triggers(self, on_config: Any) -> List[str]:
        """æå–è§¦å‘æ¡ä»¶"""
        triggers = []
        
        if isinstance(on_config, dict):
            for key in on_config.keys():
                if key == 'schedule':
                    cron_jobs = on_config[key]
                    if isinstance(cron_jobs, list):
                        for job in cron_jobs:
                            if isinstance(job, dict) and 'cron' in job:
                                triggers.append(f"schedule({job['cron']})")
                elif key == 'push':
                    triggers.append('push')
                elif key == 'pull_request':
                    triggers.append('pull_request')
                elif key == 'workflow_dispatch':
                    triggers.append('manual')
                else:
                    triggers.append(key)
        elif isinstance(on_config, str):
            triggers.append(on_config)
        
        return triggers
    
    def _validate_workflow_config(self, workflow: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯å·¥ä½œæµé…ç½®"""
        jobs = workflow.get('jobs', {})
        
        for job_name, job_config in jobs.items():
            if not isinstance(job_config, dict):
                result['issues'].append(f"ä½œä¸š {job_name} é…ç½®æ ¼å¼é”™è¯¯")
                continue
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if 'runs-on' not in job_config:
                result['issues'].append(f"ä½œä¸š {job_name} ç¼ºå°‘ runs-on å­—æ®µ")
            
            # æ£€æŸ¥æ­¥éª¤
            steps = job_config.get('steps', [])
            if not steps:
                result['warnings'].append(f"ä½œä¸š {job_name} æ²¡æœ‰å®šä¹‰æ­¥éª¤")
            else:
                self._validate_job_steps(job_name, steps, result)
            
            # æ£€æŸ¥æƒé™è®¾ç½®
            permissions = job_config.get('permissions')
            if permissions:
                self._validate_permissions(job_name, permissions, result)
    
    def _validate_job_steps(self, job_name: str, steps: List[Dict[str, Any]], result: Dict[str, Any]):
        """éªŒè¯ä½œä¸šæ­¥éª¤"""
        for i, step in enumerate(steps):
            if not isinstance(step, dict):
                result['issues'].append(f"ä½œä¸š {job_name} çš„æ­¥éª¤ {i+1} æ ¼å¼é”™è¯¯")
                continue
            
            # æ£€æŸ¥æ­¥éª¤åç§°
            if 'name' not in step:
                result['warnings'].append(f"ä½œä¸š {job_name} çš„æ­¥éª¤ {i+1} ç¼ºå°‘åç§°")
            
            # æ£€æŸ¥åŠ¨ä½œæˆ–è¿è¡Œå‘½ä»¤
            if 'uses' not in step and 'run' not in step:
                result['issues'].append(f"ä½œä¸š {job_name} çš„æ­¥éª¤ {i+1} ç¼ºå°‘ uses æˆ– run å­—æ®µ")
    
    def _validate_permissions(self, job_name: str, permissions: Any, result: Dict[str, Any]):
        """éªŒè¯æƒé™è®¾ç½®"""
        if isinstance(permissions, dict):
            for perm, value in permissions.items():
                if value not in ['read', 'write', 'none']:
                    result['warnings'].append(f"ä½œä¸š {job_name} çš„æƒé™ {perm} å€¼å¯èƒ½æ— æ•ˆ: {value}")
    
    def _validate_referenced_scripts(self, workflow: Dict[str, Any], result: Dict[str, Any]):
        """éªŒè¯å¼•ç”¨çš„è„šæœ¬æ–‡ä»¶"""
        jobs = workflow.get('jobs', {})
        
        for job_name, job_config in jobs.items():
            steps = job_config.get('steps', [])
            
            for step in steps:
                if 'run' in step:
                    run_command = step['run']
                    self._check_script_references(job_name, step.get('name', 'unnamed'), run_command, result)
    
    def _check_script_references(self, job_name: str, step_name: str, run_command: str, result: Dict[str, Any]):
        """æ£€æŸ¥è¿è¡Œå‘½ä»¤ä¸­å¼•ç”¨çš„è„šæœ¬"""
        # æŸ¥æ‰¾Pythonè„šæœ¬å¼•ç”¨
        python_scripts = re.findall(r'python\s+scripts/([^\s]+\.py)', run_command)
        
        for script in python_scripts:
            script_path = self.repo_root / 'scripts' / script
            if not script_path.exists():
                result['issues'].append(f"ä½œä¸š {job_name} æ­¥éª¤ '{step_name}' å¼•ç”¨çš„è„šæœ¬ä¸å­˜åœ¨: scripts/{script}")
            else:
                print(f"    âœ… æ‰¾åˆ°å¼•ç”¨è„šæœ¬: scripts/{script}")
    
    def test_python_scripts(self) -> Dict[str, Any]:
        """æµ‹è¯•å·¥ä½œæµä¸­å¼•ç”¨çš„Pythonè„šæœ¬"""
        print(f"\nğŸ æµ‹è¯•Pythonè„šæœ¬åŠŸèƒ½...")
        
        script_results = {}
        
        # æµ‹è¯•ä¸»è¦è„šæœ¬
        scripts_to_test = [
            ('check-syntax.py', self._test_syntax_checker),
            ('crypto-project-analyzer.py', self._test_crypto_analyzer),
            ('claude_prompts_analyzer.py', self._test_prompts_analyzer)
        ]
        
        for script_name, test_func in scripts_to_test:
            script_path = self.repo_root / 'scripts' / script_name
            print(f"\nğŸ“„ æµ‹è¯•è„šæœ¬: {script_name}")
            
            if not script_path.exists():
                script_results[script_name] = {
                    'exists': False,
                    'error': f"è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script_path}"
                }
                print(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨")
                continue
            
            try:
                result = test_func(script_path)
                script_results[script_name] = result
            except Exception as e:
                script_results[script_name] = {
                    'exists': True,
                    'error': str(e)
                }
                print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
        
        return script_results
    
    def _test_syntax_checker(self, script_path: Path) -> Dict[str, Any]:
        """æµ‹è¯•è¯­æ³•æ£€æŸ¥å™¨"""
        import subprocess
        
        try:
            # åªåšè¯­æ³•æ£€æŸ¥ï¼Œä¸å®é™…è¿è¡Œ
            result = subprocess.run([
                'python', '-m', 'py_compile', str(script_path)
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                print("  âœ… è¯­æ³•æ£€æŸ¥é€šè¿‡")
                return {'exists': True, 'syntax_valid': True}
            else:
                print(f"  âŒ è¯­æ³•é”™è¯¯: {result.stderr}")
                return {'exists': True, 'syntax_valid': False, 'error': result.stderr}
                
        except subprocess.TimeoutExpired:
            return {'exists': True, 'syntax_valid': False, 'error': 'Timeout during syntax check'}
    
    def _test_crypto_analyzer(self, script_path: Path) -> Dict[str, Any]:
        """æµ‹è¯•åŠ å¯†é¡¹ç›®åˆ†æå™¨"""
        return self._test_script_import(script_path, 'crypto-project-analyzer')
    
    def _test_prompts_analyzer(self, script_path: Path) -> Dict[str, Any]:
        """æµ‹è¯•æç¤ºè¯åˆ†æå™¨"""
        return self._test_script_import(script_path, 'claude_prompts_analyzer')
    
    def _test_script_import(self, script_path: Path, module_name: str) -> Dict[str, Any]:
        """æµ‹è¯•è„šæœ¬å¯¼å…¥å’ŒåŸºæœ¬ç»“æ„"""
        import subprocess
        import sys
        
        try:
            # æµ‹è¯•è„šæœ¬å¯¼å…¥
            test_code = f'''
import sys
sys.path.insert(0, "{self.repo_root / 'scripts'}")

try:
    import importlib.util
    spec = importlib.util.spec_from_file_location("{module_name}", "{script_path}")
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    print("IMPORT_SUCCESS")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰mainå‡½æ•°
    if hasattr(module, 'main'):
        print("HAS_MAIN")
    else:
        print("NO_MAIN")
        
except Exception as e:
    print(f"IMPORT_ERROR: {{e}}")
'''
            
            result = subprocess.run([
                sys.executable, '-c', test_code
            ], capture_output=True, text=True, timeout=30)
            
            output = result.stdout.strip()
            
            if 'IMPORT_SUCCESS' in output:
                has_main = 'HAS_MAIN' in output
                print(f"  âœ… å¯¼å…¥æˆåŠŸ {'(æœ‰mainå‡½æ•°)' if has_main else '(æ— mainå‡½æ•°)'}")
                return {
                    'exists': True,
                    'importable': True,
                    'has_main': has_main,
                    'syntax_valid': True
                }
            else:
                error_info = output if output else result.stderr
                print(f"  âŒ å¯¼å…¥å¤±è´¥: {error_info}")
                return {
                    'exists': True,
                    'importable': False,
                    'error': error_info
                }
                
        except subprocess.TimeoutExpired:
            return {'exists': True, 'importable': False, 'error': 'Import test timeout'}
        except Exception as e:
            return {'exists': True, 'importable': False, 'error': str(e)}
    
    def simulate_workflow_execution(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿå·¥ä½œæµæ‰§è¡Œç¯å¢ƒ"""
        print(f"\nğŸ­ æ¨¡æ‹Ÿå·¥ä½œæµæ‰§è¡Œç¯å¢ƒ...")
        
        simulation_results = {}
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        env_check = self._check_environment_variables()
        simulation_results['environment'] = env_check
        
        # æ£€æŸ¥ä¾èµ–é¡¹
        deps_check = self._check_dependencies()
        simulation_results['dependencies'] = deps_check
        
        # æ£€æŸ¥æ–‡ä»¶ç»“æ„
        structure_check = self._check_file_structure()
        simulation_results['file_structure'] = structure_check
        
        # æµ‹è¯•å…³é”®å‘½ä»¤
        commands_check = self._test_key_commands()
        simulation_results['commands'] = commands_check
        
        return simulation_results
    
    def _check_environment_variables(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç¯å¢ƒå˜é‡"""
        print("  ğŸ“‹ æ£€æŸ¥ç¯å¢ƒå˜é‡...")
        
        required_vars = ['GITHUB_TOKEN', 'GITHUB_ACTIONS']
        optional_vars = ['DAYS_BACK', 'MAX_PROJECTS']
        
        env_status = {
            'required': {},
            'optional': {},
            'all_required_present': True
        }
        
        for var in required_vars:
            is_set = var in os.environ
            env_status['required'][var] = is_set
            if not is_set:
                env_status['all_required_present'] = False
                print(f"    âš ï¸  ç¼ºå°‘å¿…éœ€ç¯å¢ƒå˜é‡: {var}")
            else:
                print(f"    âœ… æ‰¾åˆ°ç¯å¢ƒå˜é‡: {var}")
        
        for var in optional_vars:
            env_status['optional'][var] = var in os.environ
            if var in os.environ:
                print(f"    âœ… æ‰¾åˆ°å¯é€‰ç¯å¢ƒå˜é‡: {var}")
        
        return env_status
    
    def _check_dependencies(self) -> Dict[str, Any]:
        """æ£€æŸ¥Pythonä¾èµ–"""
        print("  ğŸ“¦ æ£€æŸ¥Pythonä¾èµ–...")
        
        requirements_file = self.repo_root / 'scripts' / 'requirements.txt'
        deps_status = {'requirements_file_exists': False, 'dependencies': {}}
        
        if not requirements_file.exists():
            print(f"    âŒ requirements.txt æ–‡ä»¶ä¸å­˜åœ¨")
            return deps_status
        
        deps_status['requirements_file_exists'] = True
        
        try:
            with open(requirements_file, 'r', encoding='utf-8') as f:
                requirements = f.read().strip()
            
            # æå–åŒ…å
            import re
            packages = []
            for line in requirements.split('\n'):
                line = line.strip()
                if line and not line.startswith('#'):
                    # æå–åŒ…åï¼ˆå»æ‰ç‰ˆæœ¬è¦æ±‚ï¼‰
                    match = re.match(r'^([a-zA-Z0-9_-]+)', line)
                    if match:
                        packages.append(match.group(1))
            
            # æ£€æŸ¥æ¯ä¸ªåŒ…æ˜¯å¦å¯å¯¼å…¥
            for package in packages:
                try:
                    __import__(package)
                    deps_status['dependencies'][package] = True
                    print(f"    âœ… {package} - å·²å®‰è£…")
                except ImportError:
                    deps_status['dependencies'][package] = False
                    print(f"    âŒ {package} - æœªå®‰è£…")
                    
        except Exception as e:
            print(f"    âŒ è¯»å–requirements.txtå¤±è´¥: {e}")
        
        return deps_status
    
    def _check_file_structure(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ–‡ä»¶ç»“æ„"""
        print("  ğŸ“ æ£€æŸ¥æ–‡ä»¶ç»“æ„...")
        
        required_paths = [
            'scripts/',
            'content/',
            'content/posts/',
            'data/',
            'themes/',
            'hugo.toml'
        ]
        
        structure_status = {}
        all_present = True
        
        for path in required_paths:
            full_path = self.repo_root / path
            exists = full_path.exists()
            structure_status[path] = exists
            
            if exists:
                print(f"    âœ… {path}")
            else:
                print(f"    âŒ {path} - ä¸å­˜åœ¨")
                all_present = False
        
        structure_status['all_required_present'] = all_present
        return structure_status
    
    def _test_key_commands(self) -> Dict[str, Any]:
        """æµ‹è¯•å…³é”®å‘½ä»¤"""
        print("  ğŸ”§ æµ‹è¯•å…³é”®å‘½ä»¤...")
        
        commands = {
            'python': ['python', '--version'],
            'hugo': ['hugo', 'version'],
            'git': ['git', '--version']
        }
        
        command_results = {}
        
        for name, cmd in commands.items():
            try:
                import subprocess
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                
                if result.returncode == 0:
                    version = result.stdout.strip().split('\n')[0]
                    command_results[name] = {'available': True, 'version': version}
                    print(f"    âœ… {name}: {version}")
                else:
                    command_results[name] = {'available': False, 'error': result.stderr.strip()}
                    print(f"    âŒ {name}: {result.stderr.strip()}")
                    
            except subprocess.TimeoutExpired:
                command_results[name] = {'available': False, 'error': 'Timeout'}
                print(f"    âŒ {name}: è¶…æ—¶")
            except FileNotFoundError:
                command_results[name] = {'available': False, 'error': 'Command not found'}
                print(f"    âŒ {name}: å‘½ä»¤æœªæ‰¾åˆ°")
            except Exception as e:
                command_results[name] = {'available': False, 'error': str(e)}
                print(f"    âŒ {name}: {e}")
        
        return command_results
    
    def _create_summary(self) -> Dict[str, Any]:
        """åˆ›å»ºéªŒè¯æ‘˜è¦"""
        total_files = len(self.validation_results)
        valid_files = sum(1 for r in self.validation_results if r['valid_yaml'] and r['valid_structure'])
        total_issues = sum(len(r['issues']) for r in self.validation_results)
        total_warnings = sum(len(r['warnings']) for r in self.validation_results)
        
        return {
            'summary': {
                'total_files': total_files,
                'valid_files': valid_files,
                'total_issues': total_issues,
                'total_warnings': total_warnings,
                'success_rate': (valid_files / total_files * 100) if total_files > 0 else 0
            },
            'files': self.validation_results,
            'global_issues': self.issues,
            'global_warnings': self.warnings
        }
    
    def generate_report(self, output_file: str = None) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        workflow_validation = self.validate_all_workflows()
        script_tests = self.test_python_scripts()
        simulation = self.simulate_workflow_execution()
        
        # ç”ŸæˆæŠ¥å‘Š
        report_lines = []
        
        # æ ‡é¢˜
        report_lines.append("GitHub å·¥ä½œæµå…¨é¢æµ‹è¯•æŠ¥å‘Š")
        report_lines.append("=" * 50)
        report_lines.append(f"æµ‹è¯•æ—¶é—´: {os.popen('date').read().strip()}")
        report_lines.append(f"æµ‹è¯•ç›®å½•: {self.workflows_dir}")
        report_lines.append("")
        
        # å·¥ä½œæµéªŒè¯ç»“æœ
        report_lines.append("ğŸ“‹ å·¥ä½œæµæ–‡ä»¶éªŒè¯")
        report_lines.append("-" * 30)
        summary = workflow_validation['summary']
        report_lines.append(f"æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        report_lines.append(f"æœ‰æ•ˆæ–‡ä»¶: {summary['valid_files']}")
        report_lines.append(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        report_lines.append(f"é—®é¢˜æ€»æ•°: {summary['total_issues']}")
        report_lines.append(f"è­¦å‘Šæ€»æ•°: {summary['total_warnings']}")
        report_lines.append("")
        
        # è¯¦ç»†æ–‡ä»¶ä¿¡æ¯
        for file_result in workflow_validation['files']:
            status = "âœ…" if file_result['valid_yaml'] and file_result['valid_structure'] else "âŒ"
            report_lines.append(f"{status} {file_result['file']}")
            
            if file_result['summary']:
                s = file_result['summary']
                report_lines.append(f"  åç§°: {s['name']}")
                report_lines.append(f"  è§¦å‘: {', '.join(s['triggers'])}")
                report_lines.append(f"  ä½œä¸š: {s['jobs_count']} ä¸ª")
            
            if file_result['issues']:
                for issue in file_result['issues']:
                    report_lines.append(f"  âŒ {issue}")
            
            if file_result['warnings']:
                for warning in file_result['warnings']:
                    report_lines.append(f"  âš ï¸  {warning}")
            
            report_lines.append("")
        
        # Pythonè„šæœ¬æµ‹è¯•ç»“æœ
        report_lines.append("ğŸ Pythonè„šæœ¬æµ‹è¯•")
        report_lines.append("-" * 30)
        
        for script_name, result in script_tests.items():
            if result.get('exists', False):
                if result.get('syntax_valid', False) and result.get('importable', True):
                    status = "âœ…"
                else:
                    status = "âŒ"
            else:
                status = "âŒ"
            
            report_lines.append(f"{status} {script_name}")
            
            if 'error' in result:
                report_lines.append(f"  é”™è¯¯: {result['error']}")
            elif result.get('importable', False):
                report_lines.append(f"  å¯¼å…¥: æˆåŠŸ")
                if result.get('has_main', False):
                    report_lines.append(f"  mainå‡½æ•°: å­˜åœ¨")
            
        report_lines.append("")
        
        # ç¯å¢ƒæ¨¡æ‹Ÿç»“æœ
        report_lines.append("ğŸ­ ç¯å¢ƒæ¨¡æ‹Ÿæµ‹è¯•")
        report_lines.append("-" * 30)
        
        # ç¯å¢ƒå˜é‡
        env_result = simulation['environment']
        missing_required = [var for var, present in env_result['required'].items() if not present]
        if missing_required:
            report_lines.append(f"âŒ ç¼ºå°‘å¿…éœ€ç¯å¢ƒå˜é‡: {', '.join(missing_required)}")
        else:
            report_lines.append("âœ… æ‰€æœ‰å¿…éœ€ç¯å¢ƒå˜é‡å·²è®¾ç½®")
        
        # ä¾èµ–é¡¹
        deps_result = simulation['dependencies']
        if deps_result['requirements_file_exists']:
            missing_deps = [pkg for pkg, installed in deps_result['dependencies'].items() if not installed]
            if missing_deps:
                report_lines.append(f"âŒ ç¼ºå°‘Pythonä¾èµ–: {', '.join(missing_deps)}")
            else:
                report_lines.append("âœ… æ‰€æœ‰Pythonä¾èµ–å·²å®‰è£…")
        else:
            report_lines.append("âŒ requirements.txt æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ–‡ä»¶ç»“æ„
        structure_result = simulation['file_structure']
        if structure_result['all_required_present']:
            report_lines.append("âœ… æ–‡ä»¶ç»“æ„å®Œæ•´")
        else:
            missing_paths = [path for path, exists in structure_result.items() if not exists and path != 'all_required_present']
            report_lines.append(f"âŒ ç¼ºå°‘æ–‡ä»¶/ç›®å½•: {', '.join(missing_paths)}")
        
        # å‘½ä»¤å¯ç”¨æ€§
        commands_result = simulation['commands']
        unavailable_commands = [name for name, result in commands_result.items() if not result['available']]
        if unavailable_commands:
            report_lines.append(f"âŒ å‘½ä»¤ä¸å¯ç”¨: {', '.join(unavailable_commands)}")
        else:
            report_lines.append("âœ… æ‰€æœ‰å¿…éœ€å‘½ä»¤å¯ç”¨")
        
        report_lines.append("")
        
        # æ€»ä½“è¯„ä¼°
        report_lines.append("ğŸ“Š æ€»ä½“è¯„ä¼°")
        report_lines.append("-" * 30)
        
        total_checks = 4  # å·¥ä½œæµã€è„šæœ¬ã€ç¯å¢ƒã€å‘½ä»¤
        passed_checks = 0
        
        if summary['success_rate'] >= 100:
            passed_checks += 1
        
        if all(r.get('exists', False) and r.get('syntax_valid', False) for r in script_tests.values()):
            passed_checks += 1
        
        if env_result['all_required_present']:
            passed_checks += 1
        
        if not unavailable_commands:
            passed_checks += 1
        
        overall_score = (passed_checks / total_checks) * 100
        
        if overall_score >= 90:
            grade = "ğŸŒŸ ä¼˜ç§€"
        elif overall_score >= 70:
            grade = "âœ… è‰¯å¥½"
        elif overall_score >= 50:
            grade = "âš ï¸  ä¸€èˆ¬"
        else:
            grade = "âŒ éœ€è¦æ”¹è¿›"
        
        report_lines.append(f"æ•´ä½“è¯„åˆ†: {overall_score:.1f}% - {grade}")
        report_lines.append(f"é€šè¿‡æ£€æŸ¥: {passed_checks}/{total_checks}")
        
        report_content = "\n".join(report_lines)
        
        # ä¿å­˜æŠ¥å‘Š
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            except Exception as e:
                print(f"\nâŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
        
        return report_content


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='GitHubå·¥ä½œæµéªŒè¯å·¥å…·')
    parser.add_argument('--workflows-dir', help='å·¥ä½œæµç›®å½•è·¯å¾„')
    parser.add_argument('--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['text', 'json'], default='text', help='è¾“å‡ºæ ¼å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = WorkflowValidator(args.workflows_dir)
    
    # ç”ŸæˆæŠ¥å‘Š
    if args.format == 'json':
        # JSONæ ¼å¼è¾“å‡º
        workflow_validation = validator.validate_all_workflows()
        script_tests = validator.test_python_scripts()
        simulation = validator.simulate_workflow_execution()
        
        json_result = {
            'workflow_validation': workflow_validation,
            'script_tests': script_tests,
            'simulation': simulation
        }
        
        output = json.dumps(json_result, ensure_ascii=False, indent=2)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(output)
        else:
            print(output)
    else:
        # æ–‡æœ¬æ ¼å¼è¾“å‡º
        report = validator.generate_report(args.output)
        if not args.output:
            print(report)


if __name__ == "__main__":
    main()

import requests
import json
import os
from datetime import datetime, timedelta

def check_workflow_status():
    """æ£€æŸ¥GitHub Actionså·¥ä½œæµçŠ¶æ€"""
    
    github_token = os.getenv('GITHUB_TOKEN')
    if not github_token:
        print("âš ï¸  æœªè®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡")
        return
    
    # è¿™é‡Œéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„ä»“åº“ä¿¡æ¯
    owner = "your-username"  # æ›¿æ¢ä¸ºå®é™…ç”¨æˆ·å
    repo = "smartwallex-hugo"  # æ›¿æ¢ä¸ºå®é™…ä»“åº“å
    
    headers = {
        'Authorization': f'token {github_token}',
        'Accept': 'application/vnd.github.v3+json'
    }
    
    print("ğŸ” æ£€æŸ¥GitHub Actionså·¥ä½œæµçŠ¶æ€...")
    print("=" * 50)
    
    # è·å–å·¥ä½œæµåˆ—è¡¨
    workflows_url = f"https://api.github.com/repos/{owner}/{repo}/actions/workflows"
    
    try:
        response = requests.get(workflows_url, headers=headers)
        if response.status_code != 200:
            print(f"âŒ è·å–å·¥ä½œæµåˆ—è¡¨å¤±è´¥: {response.status_code}")
            return
        
        workflows = response.json()['workflows']
        
        for workflow in workflows:
            workflow_name = workflow['name']
            workflow_id = workflow['id']
            state = workflow['state']
            
            print(f"\nğŸ“‹ å·¥ä½œæµ: {workflow_name}")
            print(f"   çŠ¶æ€: {'âœ… æ´»è·ƒ' if state == 'active' else 'âŒ éæ´»è·ƒ'}")
            
            # è·å–æœ€è¿‘çš„è¿è¡Œè®°å½•
            runs_url = f"https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs"
            runs_response = requests.get(f"{runs_url}?per_page=5", headers=headers)
            
            if runs_response.status_code == 200:
                runs = runs_response.json()['workflow_runs']
                
                if runs:
                    latest_run = runs[0]
                    status = latest_run['status']
                    conclusion = latest_run['conclusion']
                    created_at = datetime.fromisoformat(latest_run['created_at'].replace('Z', '+00:00'))
                    
                    print(f"   æœ€è¿‘è¿è¡Œ: {created_at.strftime('%Y-%m-%d %H:%M:%S')}")
                    print(f"   è¿è¡ŒçŠ¶æ€: {get_status_emoji(status, conclusion)} {status}")
                    if conclusion:
                        print(f"   è¿è¡Œç»“æœ: {get_conclusion_emoji(conclusion)} {conclusion}")
                    
                    # æ˜¾ç¤ºæœ€è¿‘5æ¬¡è¿è¡Œçš„ç»Ÿè®¡
                    success_count = sum(1 for run in runs if run['conclusion'] == 'success')
                    failure_count = sum(1 for run in runs if run['conclusion'] == 'failure')
                    
                    print(f"   æœ€è¿‘5æ¬¡: âœ… {success_count} æˆåŠŸ, âŒ {failure_count} å¤±è´¥")
                else:
                    print("   æœ€è¿‘è¿è¡Œ: æ— è¿è¡Œè®°å½•")
            else:
                print(f"   âš ï¸  è·å–è¿è¡Œè®°å½•å¤±è´¥: {runs_response.status_code}")
    
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")

def get_status_emoji(status, conclusion):
    """è·å–çŠ¶æ€è¡¨æƒ…ç¬¦å·"""
    if status == 'completed':
        if conclusion == 'success':
            return 'âœ…'
        elif conclusion == 'failure':
            return 'âŒ'
        elif conclusion == 'cancelled':
            return 'â¹ï¸'
        else:
            return 'âš ï¸'
    elif status == 'in_progress':
        return 'ğŸ”„'
    elif status == 'queued':
        return 'â³'
    else:
        return 'â“'

def get_conclusion_emoji(conclusion):
    """è·å–ç»“è®ºè¡¨æƒ…ç¬¦å·"""
    emoji_map = {
        'success': 'âœ…',
        'failure': 'âŒ',
        'cancelled': 'â¹ï¸',
        'skipped': 'â­ï¸',
        'timed_out': 'â°',
        'action_required': 'ğŸ””'
    }
    return emoji_map.get(conclusion, 'â“')

def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
    print("ğŸ“‹ GitHub Actions å·¥ä½œæµçŠ¶æ€æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    print("ä½¿ç”¨æ–¹æ³•:")
    print("1. è®¾ç½®ç¯å¢ƒå˜é‡: export GITHUB_TOKEN=your_token")
    print("2. ä¿®æ”¹è„šæœ¬ä¸­çš„ownerå’Œrepoå˜é‡")
    print("3. è¿è¡Œ: python scripts/check-workflows.py")
    print()
    print("åŠŸèƒ½:")
    print("- æ£€æŸ¥æ‰€æœ‰å·¥ä½œæµçš„çŠ¶æ€")
    print("- æ˜¾ç¤ºæœ€è¿‘çš„è¿è¡Œè®°å½•")
    print("- ç»Ÿè®¡æˆåŠŸ/å¤±è´¥æ¬¡æ•°")

if __name__ == "__main__":
    if not os.getenv('GITHUB_TOKEN'):
        show_usage()
    else:
        check_workflow_status()