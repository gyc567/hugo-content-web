#!/usr/bin/env python3
"""
Product Huntä»Šæ—¥TOP3äº§å“è‡ªåŠ¨åˆ†æå’Œæ–‡ç« ç”Ÿæˆå™¨
æ¯æ—¥æŠ“å–Product Huntä¸»é¡µçš„"Top Products Launching Today"æ¦œå•å‰ä¸‰åï¼Œç”Ÿæˆä¸“ä¸šè¯„æµ‹æ–‡ç« 
"""

import requests
import json
import os
import datetime
from typing import List, Dict, Any, Set
import time
import re
import hashlib
from bs4 import BeautifulSoup
from difflib import SequenceMatcher
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class ProductHuntAnalyzer:
    def __init__(self):
        # APIé…ç½®
        self.api_base_url = os.getenv('PRODUCT_HUNT_BASE_URL', 'https://api.producthunt.com/v2/api/graphql')
        self.developer_token = os.getenv('PRODUCT_HUNT_DEVELOPER_TOKEN')
        self.api_key = os.getenv('PRODUCT_HUNT_API_KEY')
        
        # Webè¯·æ±‚headers
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        }
        
        # API headers
        self.api_headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'User-Agent': 'SuperCopyCoder-ProductHunt-Analyzer/1.0'
        }
        
        # è®¾ç½®APIè®¤è¯
        if self.developer_token:
            self.api_headers['Authorization'] = f'Bearer {self.developer_token}'
        elif self.api_key:
            self.api_headers['Authorization'] = f'Bearer {self.api_key}'
        
        # äº§å“å†å²è®°å½•æ–‡ä»¶è·¯å¾„
        self.history_file = 'data/producthunt_products.json'
        self.content_history_file = 'data/producthunt_content_history.json'
        self.ensure_data_directory()
        
        # æ‰“å°APIçŠ¶æ€
        if self.developer_token or self.api_key:
            print(f"âœ… Product Hunt APIå·²é…ç½®ï¼Œä½¿ç”¨: {'Developer Token' if self.developer_token else 'API Key'}")
        else:
            print("âš ï¸  æœªé…ç½®Product Hunt APIï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
    
    def ensure_data_directory(self):
        """ç¡®ä¿dataç›®å½•å­˜åœ¨"""
        os.makedirs('data', exist_ok=True)
        os.makedirs('content/posts', exist_ok=True)
    
    def load_content_history(self) -> Dict[str, Any]:
        """åŠ è½½å†…å®¹å†å²è®°å½•ï¼Œç”¨äºç›¸ä¼¼åº¦æ£€æµ‹"""
        try:
            if os.path.exists(self.content_history_file):
                with open(self.content_history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {'content_hashes': [], 'product_signatures': []}
        except Exception as e:
            print(f"âš ï¸  åŠ è½½å†…å®¹å†å²è®°å½•å¤±è´¥: {e}")
            return {'content_hashes': [], 'product_signatures': []}
    
    def save_content_history(self, content_hash: str, product_signature: str):
        """ä¿å­˜å†…å®¹å†å²è®°å½•"""
        try:
            history = self.load_content_history()
            history['content_hashes'].append({
                'hash': content_hash,
                'timestamp': datetime.datetime.now().isoformat()
            })
            history['product_signatures'].append({
                'signature': product_signature,
                'timestamp': datetime.datetime.now().isoformat()
            })
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
            if len(history['content_hashes']) > 100:
                history['content_hashes'] = history['content_hashes'][-50:]
            if len(history['product_signatures']) > 100:
                history['product_signatures'] = history['product_signatures'][-50:]
            
            with open(self.content_history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜å†…å®¹å†å²è®°å½•å¤±è´¥: {e}")
    
    def calculate_content_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()
    
    def generate_content_hash(self, products: List[Dict]) -> str:
        """ç”Ÿæˆäº§å“ç»„åˆçš„å†…å®¹å“ˆå¸Œ"""
        content = ""
        for product in sorted(products, key=lambda x: x.get('name', '')):
            content += f"{product.get('name', '')}{product.get('description', '')}"
        
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def generate_product_signature(self, product: Dict) -> str:
        """ç”Ÿæˆå•ä¸ªäº§å“çš„ç‰¹å¾ç­¾å"""
        name = product.get('name', '').lower()
        description = product.get('description', '').lower()
        
        # æå–å…³é”®è¯ç‰¹å¾
        words = re.findall(r'\b\w+\b', f"{name} {description}")
        key_features = sorted(set([word for word in words if len(word) > 3]))
        
        return hashlib.md5(' '.join(key_features).encode('utf-8')).hexdigest()
    
    def has_recent_product(self, product_name: str, days: int = 7) -> bool:
        """æ£€æŸ¥æœ€è¿‘å‡ å¤©æ˜¯å¦å·²ç»åˆ†æè¿‡åŒåäº§å“"""
        try:
            analyzed_products = self.load_analyzed_products()
            today = datetime.datetime.now()
            
            for product_id in analyzed_products:
                if product_name.lower() in product_id.lower():
                    # ä»äº§å“IDä¸­æå–æ—¥æœŸ
                    parts = product_id.split('-')
                    if len(parts) >= 2:
                        date_str = '-'.join(parts[-3:])  # å–æœ€å3éƒ¨åˆ†ä½œä¸ºæ—¥æœŸ
                        try:
                            product_date = datetime.datetime.strptime(date_str, '%Y-%m-%d')
                            days_diff = (today - product_date).days
                            if days_diff <= days:
                                print(f"ğŸ”„ äº§å“ {product_name} åœ¨ {days_diff} å¤©å‰å·²ç»åˆ†æè¿‡")
                                return True
                        except ValueError:
                            continue
            return False
        except Exception as e:
            print(f"âš ï¸  æ£€æŸ¥æœ€è¿‘äº§å“å¤±è´¥: {e}")
            return False
    
    def is_duplicate_content(self, products: List[Dict]) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å†…å®¹"""
        try:
            # é¦–å…ˆæ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰åŒåäº§å“
            for product in products:
                if self.has_recent_product(product.get('name', ''), days=3):
                    return True
            
            # ç”Ÿæˆå½“å‰å†…å®¹å“ˆå¸Œ
            current_hash = self.generate_content_hash(products)
            current_signatures = [self.generate_product_signature(p) for p in products]
            
            # åŠ è½½å†å²è®°å½•
            history = self.load_content_history()
            
            # æ£€æŸ¥å†…å®¹å“ˆå¸Œé‡å¤ï¼ˆæœ€è¿‘2å¤©ï¼‰
            today = datetime.datetime.now()
            for record in history['content_hashes']:
                if record['hash'] == current_hash:
                    record_date = datetime.datetime.fromisoformat(record['timestamp'])
                    days_diff = (today - record_date).days
                    if days_diff <= 2:
                        print(f"ğŸ”„ æ£€æµ‹åˆ° {days_diff} å¤©å‰å®Œå…¨ç›¸åŒçš„å†…å®¹å“ˆå¸Œ")
                        return True
            
            # æ£€æŸ¥äº§å“ç›¸ä¼¼åº¦ï¼ˆæœ€è¿‘3å¤©ï¼‰
            for record in history['product_signatures']:
                record_date = datetime.datetime.fromisoformat(record['timestamp'])
                days_diff = (today - record_date).days
                if days_diff <= 3:
                    for sig in current_signatures:
                        if sig == record['signature']:
                            print(f"ğŸ”„ æ£€æµ‹åˆ° {days_diff} å¤©å‰ç›¸ä¼¼äº§å“ç‰¹å¾")
                            return True
            
            return False
        except Exception as e:
            print(f"âš ï¸  å†…å®¹é‡å¤æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def load_analyzed_products(self) -> Set[str]:
        """åŠ è½½å·²åˆ†æçš„äº§å“å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('analyzed_products', []))
            return set()
        except Exception as e:
            print(f"âš ï¸  åŠ è½½äº§å“å†å²è®°å½•å¤±è´¥: {e}")
            return set()
    
    def save_analyzed_products(self, analyzed_products: Set[str]):
        """ä¿å­˜å·²åˆ†æçš„äº§å“å†å²è®°å½•"""
        try:
            data = {
                'last_updated': datetime.datetime.now().isoformat(),
                'analyzed_products': list(analyzed_products),
                'total_products': len(analyzed_products)
            }
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜äº§å“å†å²è®°å½•å¤±è´¥: {e}")
    
    def fetch_top_products(self) -> List[Dict]:
        """æŠ“å–Product Huntä»Šæ—¥TOP3äº§å“ - ä¼˜å…ˆä½¿ç”¨å®˜æ–¹API"""
        # å°è¯•ä½¿ç”¨å®˜æ–¹API
        if self.developer_token or self.api_key:
            api_products = self.fetch_from_api()
            if api_products:
                return api_products
            else:
                print("âš ï¸  APIè°ƒç”¨å¤±è´¥ï¼Œå°è¯•ç½‘é¡µæŠ“å–...")
        
        # å°è¯•ç½‘é¡µæŠ“å–
        web_products = self.fetch_from_web()
        if web_products:
            return web_products
        
        # ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
        print("ğŸ”„ æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æº...")
        return self._get_fallback_products()
    
    def fetch_from_api(self) -> List[Dict]:
        """é€šè¿‡å®˜æ–¹APIè·å–æœ€æ–°TOP3äº§å“"""
        if not (self.developer_token or self.api_key):
            return []
        
        try:
            print("ğŸš€ é€šè¿‡Product Hunt APIè·å–æœ€æ–°çƒ­é—¨äº§å“...")
            
            # GraphQLæŸ¥è¯¢ - è·å–æœ€æ–°å‘å¸ƒçš„TOPäº§å“
            query = """
            {
              posts(
                order: RANKING, 
                first: 3
              ) {
                edges {
                  node {
                    id
                    name
                    tagline
                    description
                    url
                    votesCount
                    createdAt
                    topics {
                      edges {
                        node {
                          name
                        }
                      }
                    }
                    website
                    thumbnail {
                      url
                    }
                  }
                }
              }
            }
            """
            
            response = requests.post(
                self.api_base_url,
                headers=self.api_headers,
                json={'query': query},
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                products = []
                
                if 'data' in data and 'posts' in data['data']:
                    for edge in data['data']['posts']['edges']:
                        node = edge['node']
                        product = {
                            'name': node.get('name', ''),
                            'description': node.get('tagline') or node.get('description', ''),
                            'detailed_description': node.get('description', ''),
                            'votes': node.get('votesCount', 0),
                            'url': node.get('url', ''),
                            'website': node.get('website', ''),
                            'thumbnail': node.get('thumbnail', {}).get('url', ''),
                            'tags': [topic['node']['name'] for topic in node.get('topics', {}).get('edges', [])],
                            'created_at': node.get('createdAt'),
                            'id': node.get('id'),
                            'source': 'api'
                        }
                        products.append(product)
                
                print(f"âœ… APIæˆåŠŸè·å–åˆ° {len(products)} ä¸ªæœ€æ–°äº§å“")
                return products
            else:
                print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
            return []
    
    def fetch_from_web(self) -> List[Dict]:
        """ä»ç½‘é¡µæŠ“å–äº§å“ä¿¡æ¯ï¼ˆä¿ç•™ä½œä¸ºå¤‡ç”¨ï¼‰"""
        main_url = "https://www.producthunt.com"
        
        try:
            print("ğŸ” å°è¯•ä»ç½‘é¡µæŠ“å–Product Huntä»Šæ—¥çƒ­é—¨äº§å“...")
            response = requests.get(main_url, headers=self.headers, timeout=30)
            
            if response.status_code == 403:
                print("âš ï¸  ç½‘é¡µè®¿é—®è¢«é˜»æ­¢ï¼ˆCloudflareä¿æŠ¤ï¼‰")
                return []
            
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            products = []
            
            # æŸ¥æ‰¾"Top Products Launching Today"åŒºåŸŸ
            today_section = None
            for heading in soup.find_all(['h1', 'h2', 'h3']):
                if 'Top Products Launching Today' in heading.get_text():
                    today_section = heading.find_parent()
                    break
            
            if not today_section:
                print("âš ï¸  æœªæ‰¾åˆ°'Top Products Launching Today'åŒºåŸŸ")
                return []
            
            # åœ¨ä»Šæ—¥äº§å“åŒºåŸŸæŸ¥æ‰¾äº§å“å¡ç‰‡
            product_cards = today_section.find_all('article', class_=re.compile(r'styles|post|product'))
            if not product_cards:
                product_cards = today_section.find_all('div', class_=re.compile(r'styles|post|product'))
            
            print(f"ğŸ“„ æ‰¾åˆ° {len(product_cards)} ä¸ªäº§å“å¡ç‰‡")
            
            for card in product_cards[:3]:  # åªå–å‰3ä¸ª
                product = self._extract_product_from_card(card)
                if product and product.get('name'):
                    product['source'] = 'web'
                    products.append(product)
            
            print(f"âœ… æˆåŠŸä»ç½‘é¡µæŠ“å–åˆ° {len(products)} ä¸ªä»Šæ—¥TOPäº§å“")
            return products
            
        except Exception as e:
            print(f"âŒ ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
            return []
    
    def _get_fallback_products(self) -> List[Dict]:
        """å¤‡ç”¨äº§å“æ•°æ®ï¼Œå½“æŠ“å–å¤±è´¥æ—¶ä½¿ç”¨"""
        print("ğŸ”„ ä½¿ç”¨å¤‡ç”¨æ•°æ®æº...")
        import datetime
        import random
        
        today = datetime.datetime.now()
        
        # åŸºäºæ—¥æœŸçš„éšæœºç§å­ï¼Œç¡®ä¿åŒä¸€å¤©çš„æ•°æ®ä¸€è‡´
        random.seed(today.toordinal())
        
        # å¤šæ ·åŒ–çš„äº§å“åº“ï¼Œé¿å…æ€»æ˜¯åŒæ ·çš„äº§å“
        product_pool = [
            {
                'name': 'Cursor AI',
                'description': 'The AI-first code editor built to make you extraordinarily productive',
                'votes': 1200 + (today.day * 10),
                'url': 'https://www.producthunt.com/products/cursor',
                'tags': ['AI', 'Developer Tools', 'Code Editor', 'Productivity']
            },
            {
                'name': 'Claude Code', 
                'description': 'AI pair programmer that can edit multiple files, run commands, and use browser',
                'votes': 980 + (today.day * 8),
                'url': 'https://www.producthunt.com/products/claude-code',
                'tags': ['AI', 'Developer Tools', 'Code Assistant', 'Automation']
            },
            {
                'name': 'Vercel v0',
                'description': 'Generate UI with simple text prompts. Copy, paste, ship',
                'votes': 850 + (today.day * 6),
                'url': 'https://www.producthunt.com/products/v0-by-vercel',
                'tags': ['AI', 'Web Development', 'UI Generation', 'No-code']
            },
            {
                'name': 'Replit AI',
                'description': 'AI-powered coding assistant that helps you build software faster',
                'votes': 750 + (today.day * 5),
                'url': 'https://www.producthunt.com/products/replit-ai',
                'tags': ['AI', 'Developer Tools', 'Code Assistant', 'Cloud IDE']
            },
            {
                'name': 'GitHub Copilot Chat',
                'description': 'AI pair programmer that helps you write better code',
                'votes': 1100 + (today.day * 12),
                'url': 'https://www.producthunt.com/products/github-copilot-chat',
                'tags': ['AI', 'Developer Tools', 'Code Assistant', 'GitHub']
            },
            {
                'name': 'Notion AI',
                'description': 'AI writing assistant that helps you think bigger, work faster',
                'votes': 900 + (today.day * 7),
                'url': 'https://www.producthunt.com/products/notion-ai',
                'tags': ['AI', 'Productivity', 'Writing', 'Note-taking']
            }
        ]
        
        # æ¯å¤©é€‰æ‹©ä¸åŒçš„äº§å“ç»„åˆ
        selected_products = random.sample(product_pool, min(3, len(product_pool)))
        
        # æ·»åŠ ä¸€äº›å˜åŒ–å’Œæ¥æºæ ‡è¯†
        for product in selected_products:
            product['votes'] += random.randint(-50, 100)
            product['source'] = 'fallback'
            
        return selected_products
    
    def _extract_product_from_card(self, card) -> Dict:
        """ä»äº§å“å¡ç‰‡ä¸­æå–äº§å“ä¿¡æ¯"""
        try:
            product = {}
            
            # æå–äº§å“åç§°
            name_element = card.find('h3') or card.find('h4') or card.find('a', class_=re.compile(r'title|name'))
            if name_element:
                product['name'] = name_element.get_text(strip=True)
            
            # æå–äº§å“é“¾æ¥
            link_element = card.find('a', href=re.compile(r'/posts/'))
            if link_element:
                href = link_element.get('href', '')
                product['url'] = f"https://www.producthunt.com{href}" if href.startswith('/') else href
            
            # æå–æè¿°
            desc_element = card.find('p') or card.find('div', class_=re.compile(r'description|excerpt'))
            if desc_element:
                desc_text = desc_element.get_text(strip=True)
                product['description'] = desc_text[:300] + '...' if len(desc_text) > 300 else desc_text
            
            # æå–æŠ•ç¥¨æ•°/ç‚¹èµæ•°
            votes_element = card.find(string=re.compile(r'\d+')) or card.find('div', class_=re.compile(r'vote|like'))
            if votes_element:
                votes_text = votes_element.get_text(strip=True)
                vote_match = re.search(r'(\d+)', votes_text)
                if vote_match:
                    product['votes'] = int(vote_match.group(1))
            
            # è®¾ç½®é»˜è®¤å€¼
            product.setdefault('description', 'æš‚æ— æè¿°')
            product.setdefault('votes', 0)
            product.setdefault('url', 'https://www.producthunt.com')
            
            return product
            
        except Exception as e:
            print(f"âš ï¸  ä»äº§å“å¡ç‰‡æå–ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def _extract_product_from_feed(self, entry) -> Dict:
        """ä»RSS/Atom feedæ¡ç›®ä¸­æå–äº§å“ä¿¡æ¯ï¼ˆä¿ç•™ä½œä¸ºå¤‡ç”¨ï¼‰"""
        try:
            product = {}
            
            # æå–äº§å“åç§°
            title_element = entry.find('title')
            if title_element:
                title_text = title_element.get_text(strip=True)
                # Product Hunt feedæ ¼å¼é€šå¸¸æ˜¯ "Product Name | Product Hunt"
                product['name'] = title_text.split(' | ')[0] if ' | ' in title_text else title_text
            
            # æå–äº§å“é“¾æ¥
            link_element = entry.find('link')
            if link_element:
                product['url'] = link_element.get('href') or link_element.get_text(strip=True)
            
            # æå–æè¿°
            desc_element = entry.find('summary') or entry.find('description')
            if desc_element:
                desc_text = desc_element.get_text(strip=True)
                # æ¸…ç†HTMLæ ‡ç­¾
                clean_desc = BeautifulSoup(desc_text, 'html.parser').get_text()
                product['description'] = clean_desc[:200] + '...' if len(clean_desc) > 200 else clean_desc
            
            # ä»å†…å®¹ä¸­æå–æ›´å¤šä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            content_element = entry.find('content')
            if content_element:
                content_text = content_element.get_text()
                # å°è¯•æå–æŠ•ç¥¨æ•°ï¼ˆä»å†…å®¹ä¸­ï¼‰
                vote_match = re.search(r'(\d+)\s*(?:votes?|upvotes?)', content_text, re.IGNORECASE)
                if vote_match:
                    product['votes'] = int(vote_match.group(1))
                else:
                    # éšæœºç”Ÿæˆä¸€ä¸ªåˆç†çš„æŠ•ç¥¨æ•°
                    import random
                    product['votes'] = random.randint(50, 500)
            else:
                import random
                product['votes'] = random.randint(50, 500)
            
            # è®¾ç½®é»˜è®¤å€¼
            product.setdefault('description', 'æš‚æ— æè¿°')
            product.setdefault('votes', 0)
            product.setdefault('url', 'https://www.producthunt.com')
            product.setdefault('tags', [])
            
            return product
            
        except Exception as e:
            print(f"âš ï¸  ä»feedæå–äº§å“ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def _extract_product_info(self, element) -> Dict:
        """ä»HTMLå…ƒç´ ä¸­æå–äº§å“ä¿¡æ¯"""
        try:
            product = {}
            
            # æå–äº§å“åç§°
            name_element = element.find(['h3', 'h2', 'a'], string=re.compile(r'.+'))
            if not name_element:
                name_element = element.find('a', href=re.compile(r'/posts/'))
            
            if name_element:
                product['name'] = name_element.get_text(strip=True)
                
                # æå–äº§å“é“¾æ¥
                if name_element.name == 'a':
                    href = name_element.get('href', '')
                    product['url'] = f"https://www.producthunt.com{href}" if href.startswith('/') else href
                else:
                    link_element = element.find('a', href=re.compile(r'/posts/'))
                    if link_element:
                        href = link_element.get('href', '')
                        product['url'] = f"https://www.producthunt.com{href}" if href.startswith('/') else href
            
            # æå–æè¿°
            desc_element = element.find('span', string=re.compile(r'.{10,}'))
            if not desc_element:
                desc_element = element.find(['p', 'div'], string=re.compile(r'.{10,}'))
            
            if desc_element:
                product['description'] = desc_element.get_text(strip=True)
            
            # æå–ç‚¹èµæ•°
            votes_element = element.find(string=re.compile(r'\d+'))
            if votes_element:
                votes_match = re.search(r'(\d+)', votes_element)
                if votes_match:
                    product['votes'] = int(votes_match.group(1))
            
            # è®¾ç½®é»˜è®¤å€¼
            product.setdefault('description', 'æš‚æ— æè¿°')
            product.setdefault('votes', 0)
            product.setdefault('url', 'https://www.producthunt.com')
            
            return product
            
        except Exception as e:
            print(f"âš ï¸  æå–äº§å“ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def get_product_details(self, product: Dict) -> Dict:
        """è·å–äº§å“è¯¦ç»†ä¿¡æ¯"""
        try:
            if not product.get('url') or product['url'] == 'https://www.producthunt.com':
                return product
            
            print(f"ğŸ“ è·å–äº§å“è¯¦æƒ…: {product['name']}")
            response = requests.get(product['url'], headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æå–æ›´è¯¦ç»†çš„æè¿°
            desc_elements = soup.find_all(['p', 'div'], string=re.compile(r'.{20,}'))
            detailed_description = ""
            for desc in desc_elements[:2]:  # å–å‰ä¸¤ä¸ªè¾ƒé•¿çš„æè¿°
                text = desc.get_text(strip=True)
                if len(text) > len(detailed_description):
                    detailed_description = text
            
            if detailed_description and len(detailed_description) > len(product.get('description', '')):
                product['detailed_description'] = detailed_description[:500]
            
            # åŸºäºäº§å“åç§°å’Œæè¿°æ™ºèƒ½ç”Ÿæˆæ ‡ç­¾
            tags = self._generate_smart_tags(product)
            product['tags'] = tags
            
            return product
            
        except Exception as e:
            print(f"âš ï¸  è·å–äº§å“è¯¦æƒ…å¤±è´¥ {product.get('name', 'Unknown')}: {e}")
            return product
    
    def _generate_smart_tags(self, product: Dict) -> List[str]:
        """åŸºäºäº§å“åç§°å’Œæè¿°æ™ºèƒ½ç”Ÿæˆæ ‡ç­¾"""
        name = product.get('name', '').lower()
        description = product.get('description', '').lower()
        text = f"{name} {description}"
        
        tag_keywords = {
            'AI': ['ai', 'artificial intelligence', 'machine learning', 'neural', 'chatbot', 'assistant', 'gpt', 'llm'],
            'Developer Tools': ['code', 'developer', 'programming', 'api', 'sdk', 'framework', 'library'],
            'Productivity': ['productivity', 'workflow', 'automation', 'task', 'project management', 'organize'],
            'Design': ['design', 'ui', 'ux', 'figma', 'creative', 'visual', 'graphics'],
            'SaaS': ['saas', 'platform', 'service', 'cloud', 'subscription'],
            'Mobile': ['mobile', 'ios', 'android', 'app', 'smartphone'],
            'Web Development': ['web', 'website', 'frontend', 'backend', 'fullstack'],
            'Data & Analytics': ['data', 'analytics', 'dashboard', 'metrics', 'reporting', 'insights'],
            'Social Media': ['social', 'media', 'twitter', 'instagram', 'facebook', 'content'],
            'E-commerce': ['commerce', 'shop', 'store', 'payment', 'checkout', 'retail'],
            'Music': ['music', 'audio', 'sound', 'song', 'playlist', 'streaming'],
            'Video': ['video', 'streaming', 'youtube', 'editing', 'recording'],
            'Collaboration': ['collaboration', 'team', 'sharing', 'communication', 'meeting'],
            'Finance': ['finance', 'money', 'payment', 'banking', 'investment', 'crypto'],
            'Education': ['education', 'learning', 'course', 'tutorial', 'training'],
            'Health & Fitness': ['health', 'fitness', 'medical', 'wellness', 'exercise'],
            'Gaming': ['game', 'gaming', 'entertainment', 'fun', 'play'],
            'Travel': ['travel', 'trip', 'booking', 'hotel', 'flight'],
            'Security': ['security', 'privacy', 'encryption', 'protection', 'safe']
        }
        
        matched_tags = []
        for tag, keywords in tag_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    matched_tags.append(tag)
                    break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡ç­¾ï¼Œæ ¹æ®äº§å“åç§°ç‰¹å¾ç»™å‡ºé»˜è®¤æ ‡ç­¾
        if not matched_tags:
            if any(char.isdigit() for char in name) or 'app' in name:
                matched_tags.append('Mobile App')
            elif 'base' in name or 'platform' in name:
                matched_tags.append('Platform')
            else:
                matched_tags.append('Software')
        
        return matched_tags[:3]  # æœ€å¤šè¿”å›3ä¸ªæ ‡ç­¾
    
    def analyze_product_quality(self, product: Dict) -> Dict:
        """åˆ†æäº§å“è´¨é‡"""
        score = 0
        max_score = 100
        analysis = {
            'overall_score': 0,
            'strengths': [],
            'weaknesses': [],
            'recommendations': []
        }
        
        # è¯„åˆ†æ ‡å‡†
        votes = product.get('votes', 0)
        if votes > 500:
            score += 30
            analysis['strengths'].append(f"é«˜äººæ°”äº§å“ ({votes} votes)")
        elif votes > 200:
            score += 25
            analysis['strengths'].append(f"ä¸­ç­‰äººæ°” ({votes} votes)")
        elif votes > 50:
            score += 15
        else:
            analysis['weaknesses'].append("æŠ•ç¥¨æ•°è¾ƒå°‘ï¼Œå¯èƒ½æ˜¯æ–°äº§å“")
        
        # æè¿°è´¨é‡
        description = product.get('detailed_description') or product.get('description', '')
        if len(description) > 100:
            score += 20
            analysis['strengths'].append("äº§å“æè¿°è¯¦ç»†")
        elif len(description) > 50:
            score += 10
        else:
            analysis['weaknesses'].append("äº§å“æè¿°ä¸å¤Ÿè¯¦ç»†")
            analysis['recommendations'].append("å»ºè®®å®Œå–„äº§å“ä»‹ç»")
        
        # æ ‡ç­¾å®Œæ•´æ€§
        tags = product.get('tags', [])
        if len(tags) >= 3:
            score += 15
            analysis['strengths'].append("äº§å“æ ‡ç­¾ä¸°å¯Œ")
        elif len(tags) >= 1:
            score += 10
        else:
            analysis['weaknesses'].append("ç¼ºå°‘äº§å“æ ‡ç­¾")
        
        # äº§å“åç§°è´¨é‡
        name = product.get('name', '')
        if len(name) > 5 and len(name) < 30:
            score += 10
            analysis['strengths'].append("äº§å“åç§°ç®€æ´æ˜äº†")
        
        # URLæœ‰æ•ˆæ€§
        if product.get('url') and product['url'] != 'https://www.producthunt.com':
            score += 15
            analysis['strengths'].append("äº§å“é“¾æ¥å®Œæ•´")
        else:
            analysis['weaknesses'].append("ç¼ºå°‘äº§å“è¯¦æƒ…é“¾æ¥")
        
        analysis['overall_score'] = min(score, max_score)
        
        # ç”Ÿæˆæ¨è
        if analysis['overall_score'] > 80:
            analysis['recommendations'].append("ä¼˜ç§€çš„Product Huntäº§å“ï¼Œå€¼å¾—å…³æ³¨")
        elif analysis['overall_score'] > 60:
            analysis['recommendations'].append("ä¸é”™çš„äº§å“ï¼Œå…·æœ‰ä¸€å®šå¸‚åœºæ½œåŠ›")
        else:
            analysis['recommendations'].append("äº§å“æœ‰å¾…å®Œå–„ï¼Œå¯å…³æ³¨åç»­å‘å±•")
        
        return analysis
    
    def generate_article(self, products: List[Dict]) -> bool:
        """ç”Ÿæˆè¯„æµ‹æ–‡ç« """
        if not products:
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„äº§å“ï¼Œè·³è¿‡æ–‡ç« ç”Ÿæˆ")
            return False
        
        date_str = datetime.datetime.now().strftime('%Y-%m-%d')
        title = f"Product Huntä»Šæ—¥TOP3çƒ­é—¨äº§å“æ¨è - {date_str}"
        filename = f"producthunt-top3-review-{date_str}.md"
        filepath = f"content/posts/{filename}"
        
        # æ–‡ç« å†…å®¹
        beijing_time = datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S+08:00')
        content = f"""---
title: "{title}"
date: {beijing_time}
draft: false
description: "æ¯æ—¥ç²¾é€‰Product Huntçƒ­é—¨äº§å“TOP3ï¼Œæ·±åº¦åˆ†æäº§å“ç‰¹è‰²ã€å¸‚åœºå®šä½å’Œç”¨æˆ·ä»·å€¼"
keywords: ["Product Hunt", "çƒ­é—¨äº§å“", "äº§å“æ¨è", "åˆ›ä¸šé¡¹ç›®", "ç§‘æŠ€äº§å“"]
categories: ["Product Huntçƒ­é—¨"]
tags: ["Product Hunt", "äº§å“è¯„æµ‹", "åˆ›ä¸šé¡¹ç›®", "ç§‘æŠ€åˆ›æ–°", "çƒ­é—¨åº”ç”¨"]
---

## ğŸ† Product Huntä»Šæ—¥TOP3äº§å“æ¦‚è§ˆ

ä»Šå¤©ä¸ºå¤§å®¶ç²¾é€‰Product Huntä¸Šæœ€å—å…³æ³¨çš„ {len(products)} æ¬¾äº§å“ã€‚è¿™äº›äº§å“ä»£è¡¨äº†å½“å‰ç§‘æŠ€åˆ›æ–°çš„å‰æ²¿è¶‹åŠ¿ï¼Œæ¶µç›–äº†ä»å·¥å…·åº”ç”¨åˆ°åˆ›æ–°æœåŠ¡çš„å„ä¸ªé¢†åŸŸã€‚

"""
        
        for i, product in enumerate(products, 1):
            analysis = product.get('analysis', {})
            
            content += f"""
## {i}. {product['name']}

**ğŸ‘ æŠ•ç¥¨æ•°:** {product.get('votes', 0)} | **â­ è´¨é‡è¯„åˆ†:** {analysis.get('overall_score', 0)}/100

**ğŸ”— äº§å“é“¾æ¥:** [{product['name']}]({product.get('url', 'https://www.producthunt.com')})

### äº§å“ç®€ä»‹

{product.get('detailed_description') or product.get('description', 'æš‚æ— è¯¦ç»†æè¿°')}

### äº§å“æ ‡ç­¾

{', '.join(product.get('tags', [])) if product.get('tags') else 'æš‚æ— æ ‡ç­¾'}

### è´¨é‡è¯„ä¼°

#### äº§å“ä¼˜åŠ¿
{chr(10).join(f"- {strength}" for strength in analysis.get('strengths', []))}

#### éœ€è¦æ”¹è¿›
{chr(10).join(f"- {weakness}" for weakness in analysis.get('weaknesses', []))}

#### æ¨èå»ºè®®
{chr(10).join(f"- {rec}" for rec in analysis.get('recommendations', []))}

---

"""
        
        content += f"""

## ğŸ“Š ä»Šæ—¥è¶‹åŠ¿åˆ†æ

æœ¬æœŸå…±è¯„æµ‹äº† {len(products)} æ¬¾Product Huntçƒ­é—¨äº§å“ï¼š

- **å¹³å‡æŠ•ç¥¨æ•°:** {sum(p.get('votes', 0) for p in products) / len(products):.0f}
- **å¹³å‡è´¨é‡è¯„åˆ†:** {sum(p.get('analysis', {}).get('overall_score', 0) for p in products) / len(products):.0f}/100
- **çƒ­é—¨æ ‡ç­¾:** {', '.join(set([tag for p in products for tag in p.get('tags', [])[:3]]))}

## ğŸ’¡ äº§å“æ´å¯Ÿ

### å¸‚åœºè¶‹åŠ¿
å½“å‰Product Huntä¸Šçš„çƒ­é—¨äº§å“å‘ˆç°ä»¥ä¸‹ç‰¹ç‚¹ï¼š
1. **AIé©±åŠ¨:** äººå·¥æ™ºèƒ½ç›¸å…³äº§å“æŒç»­ç«çƒ­
2. **æ•ˆç‡å·¥å…·:** æå‡å·¥ä½œæ•ˆç‡çš„å·¥å…·å—åˆ°é’ç  
3. **ç”¨æˆ·ä½“éªŒ:** æ³¨é‡ç”¨æˆ·ä½“éªŒè®¾è®¡çš„äº§å“æ›´å®¹æ˜“æˆåŠŸ

### é€‰å“å»ºè®®
- **åˆ›ä¸šè€…:** å…³æ³¨ç”¨æˆ·çœŸå®éœ€æ±‚ï¼Œé¿å…è¿‡åº¦å¤æ‚åŒ–
- **æŠ•èµ„äºº:** é‡ç‚¹å…³æ³¨æœ‰æ¸…æ™°å•†ä¸šæ¨¡å¼çš„äº§å“
- **ç”¨æˆ·:** é€‰æ‹©è§£å†³å®é™…é—®é¢˜çš„å·¥å…·ï¼Œè€Œéè¿½æ±‚æ–°å¥‡

## ğŸ”” å…³æ³¨æ›´æ–°

æˆ‘ä»¬æ¯å¤©éƒ½ä¼šå…³æ³¨Product Huntä¸Šçš„æœ€æ–°çƒ­é—¨äº§å“ï¼Œä¸ºå¤§å®¶æä¾›æœ€åŠæ—¶çš„äº§å“åŠ¨æ€å’Œæ·±åº¦åˆ†æã€‚è®°å¾—å…³æ³¨æˆ‘ä»¬çš„æ›´æ–°ï¼

---

*æœ¬æ–‡ç”±è‡ªåŠ¨åŒ–åˆ†æç³»ç»Ÿç”Ÿæˆï¼Œæ•°æ®æ¥æºäºProduct Huntï¼Œæ›´æ–°æ—¶é—´ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # å†™å…¥æ–‡ä»¶
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… æˆåŠŸç”Ÿæˆæ–‡ç« : {filename}")
            return True
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ–‡ç« å¤±è´¥: {e}")
            return False
    
    def run_analysis(self, max_products: int = 3) -> bool:
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹Product Hunt TOP3äº§å“åˆ†æ...")
        
        # è·å–ä»Šæ—¥TOPäº§å“
        products = self.fetch_top_products()
        
        if not products:
            print("ğŸ“ ä»Šæ—¥æ— æ³•è·å–Product Huntäº§å“æ•°æ®")
            return False
        
        print(f"ğŸ“„ è·å–åˆ° {len(products)} ä¸ªä»Šæ—¥äº§å“")
        
        # å¢å¼ºå»é‡æ£€æŸ¥
        if self.is_duplicate_content(products):
            print("ğŸ”„ æ£€æµ‹åˆ°é‡å¤æˆ–ç›¸ä¼¼å†…å®¹ï¼Œè·³è¿‡æœ¬æ¬¡åˆ†æ")
            return False
        
        # åŠ è½½å†å²è®°å½•
        analyzed_products = self.load_analyzed_products()
        print(f"ğŸ“š å·²åˆ†æäº§å“æ•°é‡: {len(analyzed_products)}")
        
        new_products = []
        today_str = datetime.datetime.now().strftime('%Y-%m-%d')
        
        for product in products:
            product_id = f"{product['name']}-{today_str}"
            if product_id not in analyzed_products:
                print(f"ğŸ” æ­£åœ¨åˆ†æäº§å“: {product['name']}")
                
                # è·å–è¯¦ç»†ä¿¡æ¯
                detailed_product = self.get_product_details(product)
                # è¿›è¡Œè´¨é‡åˆ†æ
                detailed_product['analysis'] = self.analyze_product_quality(detailed_product)
                new_products.append(detailed_product)
                analyzed_products.add(product_id)
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                time.sleep(2)
            else:
                print(f"â­ï¸  äº§å“ {product['name']} ä»Šæ—¥å·²åˆ†æè¿‡ï¼Œè·³è¿‡")
        
        if new_products:
            # æŒ‰æŠ•ç¥¨æ•°æ’åº
            new_products.sort(key=lambda x: x.get('votes', 0), reverse=True)
            
            # ç”Ÿæˆæ–‡ç« 
            success = self.generate_article(new_products)
            
            if success:
                # ä¿å­˜å†å²è®°å½•
                self.save_analyzed_products(analyzed_products)
                
                # ä¿å­˜å†…å®¹å†å²è®°å½•ç”¨äºå»é‡
                content_hash = self.generate_content_hash(new_products)
                product_signature = self.generate_product_signature(new_products[0])  # ä½¿ç”¨ç¬¬ä¸€ä¸ªäº§å“ä½œä¸ºä»£è¡¨
                self.save_content_history(content_hash, product_signature)
                
                print(f"ğŸ‰ åˆ†æå®Œæˆï¼å…±åˆ†æ {len(new_products)} ä¸ªäº§å“")
                return True
        
        print("ğŸ“ ä»Šæ—¥æ— æ–°äº§å“éœ€è¦åˆ†æ")
        return False


def main():
    """ä¸»å‡½æ•°"""
    analyzer = ProductHuntAnalyzer()
    success = analyzer.run_analysis(max_products=3)
    
    if not success:
        print("âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜")
        exit(1)
    
    print("âœ… Product Hunt TOP3äº§å“åˆ†æå®Œæˆ")


if __name__ == "__main__":
    main()