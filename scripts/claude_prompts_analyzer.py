#!/usr/bin/env python3
"""
Claude Code Promptsé¡¹ç›®è‡ªåŠ¨åˆ†æå’Œè¯„æµ‹ç”Ÿæˆå™¨
æ¯æ—¥æŠ“å–GitHubä¸Šæœ€çƒ­é—¨çš„Claude Code Promptsé¡¹ç›®å’Œæ•™ç¨‹ï¼Œç”Ÿæˆä¸“ä¸šè¯„æµ‹æ–‡ç« 
"""

import requests
import json
import os
import datetime
from typing import List, Dict, Any, Set
import time
import re
import hashlib

class ClaudePromptsAnalyzer:
    def __init__(self, github_token: str = None):
        self.github_token = github_token
        self.headers = {
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'Claude-Prompts-Analyzer/1.0'
        }
        if github_token:
            self.headers['Authorization'] = f'token {github_token}'
        
        # é¡¹ç›®å†å²è®°å½•æ–‡ä»¶è·¯å¾„
        self.history_file = 'data/claude_prompts_projects.json'
        self.ensure_data_directory()
        
        # Claude Codeç›¸å…³çš„æœç´¢å…³é”®è¯
        self.search_keywords = [
            'claude code',
            'claude prompts',
            'anthropic claude',
            'claude tutorial',
            'claude prompt engineering',
            'claude code examples',
            'claude ai prompts',
            'claude development'
        ]
    
    def ensure_data_directory(self):
        """ç¡®ä¿dataç›®å½•å­˜åœ¨"""
        os.makedirs('data', exist_ok=True)
        os.makedirs('content/posts', exist_ok=True)
    
    def load_analyzed_projects(self) -> Set[str]:
        """åŠ è½½å·²åˆ†æçš„é¡¹ç›®å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('analyzed_projects', []))
            return set()
        except Exception as e:
            print(f"âš ï¸  åŠ è½½é¡¹ç›®å†å²è®°å½•å¤±è´¥: {e}")
            return set()
    
    def save_analyzed_projects(self, analyzed_projects: Set[str]):
        """ä¿å­˜å·²åˆ†æçš„é¡¹ç›®å†å²è®°å½•"""
        try:
            data = {
                'last_updated': datetime.datetime.now().isoformat(),
                'analyzed_projects': list(analyzed_projects),
                'total_projects': len(analyzed_projects)
            }
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜é¡¹ç›®å†å²è®°å½•å¤±è´¥: {e}")
    
    def search_github_repositories(self, keyword: str, days_back: int = 7, per_page: int = 30) -> List[Dict]:
        """æœç´¢GitHubä»“åº“"""
        end_date = datetime.datetime.now()
        start_date = end_date - datetime.timedelta(days=days_back)
        date_filter = f"created:>{start_date.strftime('%Y-%m-%d')}"
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        query = f"{keyword} {date_filter} language:markdown OR language:python OR language:javascript"
        
        url = "https://api.github.com/search/repositories"
        params = {
            'q': query,
            'sort': 'stars',
            'order': 'desc',
            'per_page': per_page
        }
        
        try:
            print(f"ğŸ” æœç´¢å…³é”®è¯: {keyword}")
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            
            if response.status_code == 403:
                print("âš ï¸  GitHub APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…é‡è¯•...")
                time.sleep(60)
                response = requests.get(url, headers=self.headers, params=params, timeout=30)
            
            response.raise_for_status()
            data = response.json()
            
            repositories = []
            for repo in data.get('items', []):
                # è¿‡æ»¤æ‰ä¸€äº›ä¸ç›¸å…³çš„ä»“åº“
                if self._is_relevant_repository(repo, keyword):
                    repositories.append({
                        'id': repo['id'],
                        'name': repo['name'],
                        'full_name': repo['full_name'],
                        'description': repo.get('description', ''),
                        'url': repo['html_url'],
                        'stars': repo['stargazers_count'],
                        'forks': repo['forks_count'],
                        'language': repo.get('language', ''),
                        'topics': repo.get('topics', []),
                        'created_at': repo['created_at'],
                        'updated_at': repo['updated_at'],
                        'keyword': keyword
                    })
            
            print(f"âœ… æ‰¾åˆ° {len(repositories)} ä¸ªç›¸å…³ä»“åº“")
            return repositories
            
        except Exception as e:
            print(f"âŒ æœç´¢GitHubä»“åº“å¤±è´¥ ({keyword}): {e}")
            return []
    
    def _is_relevant_repository(self, repo: Dict, keyword: str) -> bool:
        """åˆ¤æ–­ä»“åº“æ˜¯å¦ä¸Claude Codeç›¸å…³"""
        name = repo.get('name', '').lower()
        description = repo.get('description', '').lower()
        topics = [topic.lower() for topic in repo.get('topics', [])]
        
        # Claudeç›¸å…³å…³é”®è¯
        claude_keywords = ['claude', 'anthropic', 'ai', 'prompt', 'assistant', 'chatbot', 'llm']
        
        # æ£€æŸ¥åç§°ã€æè¿°å’Œä¸»é¢˜ä¸­æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
        text_to_check = f"{name} {description} {' '.join(topics)}"
        
        return any(keyword in text_to_check for keyword in claude_keywords)
    
    def get_repository_details(self, repo: Dict) -> Dict:
        """è·å–ä»“åº“è¯¦ç»†ä¿¡æ¯"""
        try:
            # è·å–READMEå†…å®¹
            readme_url = f"https://api.github.com/repos/{repo['full_name']}/readme"
            readme_response = requests.get(readme_url, headers=self.headers, timeout=15)
            
            readme_content = ""
            if readme_response.status_code == 200:
                readme_data = readme_response.json()
                if readme_data.get('content'):
                    import base64
                    readme_content = base64.b64decode(readme_data['content']).decode('utf-8', errors='ignore')
                    # é™åˆ¶READMEé•¿åº¦
                    readme_content = readme_content[:2000]
            
            # è·å–æœ€æ–°çš„commits
            commits_url = f"https://api.github.com/repos/{repo['full_name']}/commits"
            commits_response = requests.get(commits_url, headers=self.headers, params={'per_page': 5}, timeout=15)
            
            recent_commits = []
            if commits_response.status_code == 200:
                commits_data = commits_response.json()
                for commit in commits_data:
                    recent_commits.append({
                        'message': commit['commit']['message'][:100],
                        'date': commit['commit']['author']['date'],
                        'author': commit['commit']['author']['name']
                    })
            
            repo['readme_content'] = readme_content
            repo['recent_commits'] = recent_commits
            
            return repo
            
        except Exception as e:
            print(f"âš ï¸  è·å–ä»“åº“è¯¦æƒ…å¤±è´¥ {repo['full_name']}: {e}")
            repo['readme_content'] = ""
            repo['recent_commits'] = []
            return repo
    
    def analyze_project_quality(self, repo: Dict) -> Dict:
        """åˆ†æé¡¹ç›®è´¨é‡"""
        score = 0
        max_score = 100
        analysis = {
            'overall_score': 0,
            'strengths': [],
            'weaknesses': [],
            'recommendations': []
        }
        
        # è¯„åˆ†æ ‡å‡†
        if repo['stars'] > 100:
            score += 20
            analysis['strengths'].append(f"é«˜äººæ°”é¡¹ç›® ({repo['stars']} stars)")
        elif repo['stars'] > 50:
            score += 15
            analysis['strengths'].append(f"ä¸­ç­‰äººæ°” ({repo['stars']} stars)")
        elif repo['stars'] > 10:
            score += 10
        else:
            analysis['weaknesses'].append("Staræ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½æ˜¯æ–°é¡¹ç›®")
        
        # READMEè´¨é‡
        readme = repo.get('readme_content', '')
        if len(readme) > 500:
            score += 15
            analysis['strengths'].append("è¯¦ç»†çš„READMEæ–‡æ¡£")
        elif len(readme) > 200:
            score += 10
        else:
            analysis['weaknesses'].append("READMEæ–‡æ¡£ä¸å¤Ÿè¯¦ç»†")
            analysis['recommendations'].append("å»ºè®®å®Œå–„é¡¹ç›®æ–‡æ¡£")
        
        # æœ€è¿‘æ´»è·ƒåº¦
        if repo.get('recent_commits'):
            recent_commit = repo['recent_commits'][0]
            commit_date = datetime.datetime.strptime(recent_commit['date'], '%Y-%m-%dT%H:%M:%SZ')
            days_since_commit = (datetime.datetime.now() - commit_date).days
            
            if days_since_commit < 30:
                score += 20
                analysis['strengths'].append("é¡¹ç›®æ´»è·ƒï¼Œæœ€è¿‘æœ‰æ›´æ–°")
            elif days_since_commit < 90:
                score += 10
            else:
                analysis['weaknesses'].append("é¡¹ç›®æ›´æ–°ä¸å¤Ÿé¢‘ç¹")
        
        # Topicså’Œæè¿°è´¨é‡
        if repo.get('topics') and len(repo['topics']) > 2:
            score += 10
            analysis['strengths'].append("é¡¹ç›®æ ‡ç­¾å®Œæ•´")
        
        if repo.get('description') and len(repo['description']) > 50:
            score += 10
            analysis['strengths'].append("é¡¹ç›®æè¿°è¯¦ç»†")
        
        # Forkæ¯”ä¾‹
        if repo['forks'] > repo['stars'] * 0.1:
            score += 15
            analysis['strengths'].append("é¡¹ç›®æœ‰è¾ƒå¥½çš„å‚ä¸åº¦")
        
        analysis['overall_score'] = min(score, max_score)
        
        # ç”Ÿæˆæ¨è
        if analysis['overall_score'] > 80:
            analysis['recommendations'].append("ä¼˜ç§€çš„Claude Codeé¡¹ç›®ï¼Œæ¨èå­¦ä¹ ")
        elif analysis['overall_score'] > 60:
            analysis['recommendations'].append("ä¸é”™çš„é¡¹ç›®ï¼Œæœ‰ä¸€å®šå­¦ä¹ ä»·å€¼")
        else:
            analysis['recommendations'].append("é¡¹ç›®æœ‰å¾…å®Œå–„ï¼Œå¯å…³æ³¨åç»­å‘å±•")
        
        return analysis
    
    def generate_article(self, projects: List[Dict]) -> bool:
        """ç”Ÿæˆè¯„æµ‹æ–‡ç« """
        if not projects:
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®ï¼Œè·³è¿‡æ–‡ç« ç”Ÿæˆ")
            return False
        
        date_str = datetime.datetime.now().strftime('%Y-%m-%d')
        title = f"GitHubä¸Šæœ€çƒ­é—¨çš„Claude Codeé¡¹ç›®è¯„æµ‹ - {date_str}"
        filename = f"github-claude-prompts-review-{date_str}.md"
        filepath = f"content/posts/{filename}"
        
        # æ–‡ç« å†…å®¹
        content = f"""---
title: "{title}"
date: {datetime.datetime.now().isoformat()}
draft: false
description: "æ¯æ—¥ç²¾é€‰GitHubä¸Šæœ€çƒ­é—¨çš„Claude Code promptsé¡¹ç›®ï¼Œæ·±åº¦åˆ†æå…¶ç‰¹ç‚¹ã€ä¼˜åŠ¿å’Œåº”ç”¨åœºæ™¯"
keywords: ["Claude Code", "GitHubçƒ­é—¨", "AI prompts", "é¡¹ç›®è¯„æµ‹", "Claudeæ•™ç¨‹"]
categories: ["GitHubçƒ­é—¨"]
tags: ["Claude Code", "AIåŠ©æ‰‹", "é¡¹ç›®è¯„æµ‹", "å¼€æºé¡¹ç›®", "prompt engineering"]
image: "/images/claude-prompts-review.jpg"
---

## ğŸ“Š ä»Šæ—¥Claude Codeçƒ­é—¨é¡¹ç›®æ¦‚è§ˆ

ä»Šå¤©ä¸ºå¤§å®¶ç²¾é€‰äº† {len(projects)} ä¸ªåœ¨GitHubä¸Šè¡¨ç°çªå‡ºçš„Claude Codeç›¸å…³é¡¹ç›®ã€‚è¿™äº›é¡¹ç›®æ¶µç›–äº†promptå·¥ç¨‹ã€å¼€å‘å·¥å…·ã€æ•™ç¨‹èµ„æºç­‰å¤šä¸ªæ–¹é¢ï¼Œä¸ºClaude Codeçš„å­¦ä¹ å’Œåº”ç”¨æä¾›äº†å®è´µçš„å‚è€ƒã€‚

"""
        
        for i, project in enumerate(projects, 1):
            analysis = project.get('analysis', {})
            
            content += f"""
## {i}. {project['name']}

**â­ GitHub Stars:** {project['stars']} | **ğŸ´ Forks:** {project['forks']} | **ğŸ“… åˆ›å»ºæ—¶é—´:** {project['created_at'][:10]}

**ğŸ”— é¡¹ç›®é“¾æ¥:** [{project['full_name']}]({project['url']})

### é¡¹ç›®ç®€ä»‹

{project.get('description', 'æš‚æ— æè¿°')}

### æŠ€æœ¯ç‰¹ç‚¹

**ä¸»è¦è¯­è¨€:** {project.get('language', 'N/A')}

**é¡¹ç›®æ ‡ç­¾:** {', '.join(project.get('topics', [])) if project.get('topics') else 'æ— '}

### è´¨é‡è¯„ä¼°

**ç»¼åˆè¯„åˆ†:** {analysis.get('overall_score', 0)}/100

#### é¡¹ç›®ä¼˜åŠ¿
{chr(10).join(f"- {strength}" for strength in analysis.get('strengths', []))}

#### éœ€è¦æ”¹è¿›
{chr(10).join(f"- {weakness}" for weakness in analysis.get('weaknesses', []))}

#### æ¨èå»ºè®®
{chr(10).join(f"- {rec}" for rec in analysis.get('recommendations', []))}

### READMEæ‘˜è¦

```
{project.get('readme_content', 'æ— READMEå†…å®¹')[:300]}...
```

### æœ€è¿‘æ›´æ–°

"""
            
            if project.get('recent_commits'):
                for commit in project['recent_commits'][:3]:
                    content += f"- **{commit['date'][:10]}** by {commit['author']}: {commit['message']}\n"
            else:
                content += "- æš‚æ— æœ€è¿‘æ›´æ–°ä¿¡æ¯\n"
            
            content += "\n---\n"
        
        content += f"""

## ğŸ“ˆ è¶‹åŠ¿åˆ†æ

æœ¬æœŸå…±åˆ†æäº† {len(projects)} ä¸ªClaude Codeç›¸å…³é¡¹ç›®ï¼š

- **å¹³å‡Staræ•°:** {sum(p['stars'] for p in projects) / len(projects):.0f}
- **å¹³å‡Forkæ•°:** {sum(p['forks'] for p in projects) / len(projects):.0f}
- **ä¸»è¦ç¼–ç¨‹è¯­è¨€:** {', '.join(set(p.get('language', 'N/A') for p in projects if p.get('language')))}

## ğŸ¯ å­¦ä¹ å»ºè®®

1. **åˆå­¦è€…:** å»ºè®®ä»æ–‡æ¡£å®Œå–„ã€Staræ•°è¾ƒé«˜çš„é¡¹ç›®å¼€å§‹å­¦ä¹ 
2. **è¿›é˜¶ç”¨æˆ·:** å¯ä»¥å…³æ³¨æœ€æ–°çš„prompt engineeringæŠ€æœ¯å’Œå·¥å…·
3. **å¼€å‘è€…:** è€ƒè™‘ä¸ºä¼˜ç§€é¡¹ç›®è´¡çŒ®ä»£ç æˆ–æå‡ºæ”¹è¿›å»ºè®®

## ğŸ”” å…³æ³¨æ›´æ–°

æˆ‘ä»¬æ¯å¤©éƒ½ä¼šæœç´¢å’Œåˆ†æGitHubä¸Šæœ€æ–°çš„Claude Codeé¡¹ç›®ï¼Œä¸ºå¤§å®¶æä¾›æœ€åŠæ—¶çš„æŠ€æœ¯åŠ¨æ€ã€‚è®°å¾—å…³æ³¨æˆ‘ä»¬çš„æ›´æ–°ï¼

---

*æœ¬æ–‡ç”±è‡ªåŠ¨åŒ–åˆ†æç³»ç»Ÿç”Ÿæˆï¼Œæ•°æ®æ¥æºäºGitHub APIï¼Œæ›´æ–°æ—¶é—´ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # å†™å…¥æ–‡ä»¶
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… æˆåŠŸç”Ÿæˆæ–‡ç« : {filename}")
            return True
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ–‡ç« å¤±è´¥: {e}")
            return False
    
    def run_analysis(self, days_back: int = 7, max_projects: int = 3) -> bool:
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹Claude Codeé¡¹ç›®åˆ†æ...")
        
        # åŠ è½½å†å²è®°å½•
        analyzed_projects = self.load_analyzed_projects()
        print(f"ğŸ“š å·²åˆ†æé¡¹ç›®æ•°é‡: {len(analyzed_projects)}")
        
        all_projects = []
        
        # æœç´¢æ‰€æœ‰å…³é”®è¯
        for keyword in self.search_keywords:
            repositories = self.search_github_repositories(keyword, days_back)
            for repo in repositories:
                # é¿å…é‡å¤åˆ†æ
                project_id = f"{repo['full_name']}-{repo['updated_at']}"
                if project_id not in analyzed_projects:
                    # è·å–è¯¦ç»†ä¿¡æ¯
                    detailed_repo = self.get_repository_details(repo)
                    # è¿›è¡Œè´¨é‡åˆ†æ
                    detailed_repo['analysis'] = self.analyze_project_quality(detailed_repo)
                    all_projects.append(detailed_repo)
                    analyzed_projects.add(project_id)
            
            # APIé™åˆ¶ï¼Œæ·»åŠ å»¶è¿Ÿ
            time.sleep(2)
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼Œé€‰æ‹©topé¡¹ç›®
        if all_projects:
            all_projects.sort(key=lambda x: x['analysis']['overall_score'], reverse=True)
            top_projects = all_projects[:max_projects]
            
            # ç”Ÿæˆæ–‡ç« 
            success = self.generate_article(top_projects)
            
            if success:
                # ä¿å­˜å†å²è®°å½•
                self.save_analyzed_projects(analyzed_projects)
                print(f"ğŸ‰ åˆ†æå®Œæˆï¼å…±åˆ†æ {len(top_projects)} ä¸ªé¡¹ç›®")
                return True
        
        print("ğŸ“ ä»Šæ—¥æ— æ–°é¡¹ç›®éœ€è¦åˆ†æ")
        return False

def main():
    """ä¸»å‡½æ•°"""
    github_token = os.getenv('GITHUB_TOKEN')
    if not github_token:
        print("âš ï¸  æœªè®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡")
    
    days_back = int(os.getenv('DAYS_BACK', 7))
    max_projects = int(os.getenv('MAX_PROJECTS', 3))
    
    analyzer = ClaudePromptsAnalyzer(github_token)
    success = analyzer.run_analysis(days_back, max_projects)
    
    if not success:
        print("âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜")
        exit(1)
    
    print("âœ… Claude Codeé¡¹ç›®åˆ†æå®Œæˆ")

if __name__ == "__main__":
    main()